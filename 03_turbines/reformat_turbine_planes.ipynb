{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cac5645-0fc0-4a14-8ef1-e8b64ce7b055",
   "metadata": {},
   "source": [
    "An approach to reformat raw output of AMR-Wind sampling planes to structured data. This code is a bit overkill, as an older version of this file was used to put together TB-sized datasets using `dask`, but we're dealing with much smaller sampling files here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c53db2d-45ee-47c4-b296-d1754a7b2b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to import google auth packages\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from netCDF4 import Dataset\n",
    "import xarray as xr\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16ee03cd-99b3-4a76-8d55-fbded152d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read in data and do some minimal processing\n",
    "parent_dir = Path('/scratch/orybchuk/wakedynamics/amr-wind-tutorial/03_turbines/post_processing')\n",
    "outdir = Path(parent_dir, 'reformatted')\n",
    "outdir.mkdir(exist_ok=True)\n",
    "t_offset = 14400\n",
    "\n",
    "fsampling = Path(parent_dir, f'sampling{t_offset}.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c98fe5-7c3d-48a1-9f53-fe32db884063",
   "metadata": {},
   "source": [
    "# Common parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14719deb-c727-4465-863f-16005371dc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "varlist: ['velocityx', 'velocityy', 'velocityz', 'temperature']\n"
     ]
    }
   ],
   "source": [
    "### Set up parameters common to all campaigns\n",
    "## User inputs\n",
    "varlist = ['velocityx', 'velocityy', 'velocityz', 'temperature']  # Manually build this\n",
    "use_dask = False\n",
    "frequency_output = 1\n",
    "\n",
    "## Data from simulations\n",
    "with h5py.File(fsampling) as f_h5py:\n",
    "    # Deal with time\n",
    "    time = f_h5py['time'][:]\n",
    "    time = np.round(time, 4)  # Round to deal with weird float behavior\n",
    "    timestep = time[1] - time[0]\n",
    "    \n",
    "    # List of variables to process\n",
    "    full_varlist = list(f_h5py['xy-domain'].keys())\n",
    "for var in varlist:\n",
    "    assert var in full_varlist, f\"Unrecognized variable {var}\"\n",
    "print(\"varlist:\", varlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbabaac-7fa0-4c4b-a4ae-44f2a5139de6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reformat domain-wide xy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61231123-f983-4726-a3bc-2d18eb0c8820",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orybchuk/.conda-envs/daskenv202301/lib/python3.9/site-packages/dask/array/core.py:1701: FutureWarning: The `numpy.sort` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  warnings.warn(\n",
      "/home/orybchuk/.conda-envs/daskenv202301/lib/python3.9/site-packages/dask/array/core.py:1701: FutureWarning: The `numpy.sort` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  warnings.warn(\n",
      "/home/orybchuk/.conda-envs/daskenv202301/lib/python3.9/site-packages/dask/array/core.py:1701: FutureWarning: The `numpy.sort` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Metadata for xy-domain\n",
    "with h5py.File(fsampling) as f_h5py:\n",
    "    f_xy = f_h5py['xy-domain']\n",
    "    ntsteps_xy = f_xy['velocityx'].shape[0]\n",
    "\n",
    "    da_xy_coords = da.from_array(f_xy['coordinates'], chunks=(-1,-1))\n",
    "    xy_xcoords = np.sort(np.unique(da_xy_coords[:,0]))\n",
    "    xy_ycoords = np.sort(np.unique(da_xy_coords[:,1]))\n",
    "    xy_zcoords = np.sort(np.unique(da_xy_coords[:,2]))\n",
    "    xy_time = np.round(np.arange(ntsteps_xy)*timestep*frequency_output,2)\n",
    "xy_coords = {'time':xy_time, 'x': xy_xcoords, 'y': xy_ycoords, 'z': xy_zcoords}\n",
    "\n",
    "## Reformat into an Xarray Dataset\n",
    "ds_xy = xr.Dataset(xy_coords)\n",
    "\n",
    "for var in varlist:\n",
    "    if use_dask:\n",
    "        raise NotImplementedError\n",
    "\n",
    "        # TODO: check the below code\n",
    "        curr_da = da.from_array(f_xy[var], chunks=chunksize_xy)\n",
    "        da_reshaped = curr_da.reshape((curr_da.shape[0], len(xy_zcoords), len(xy_ycoords), len(xy_xcoords)))\n",
    "        ds_xy[var] = (('time', 'z', 'y', 'x'), da_reshaped)\n",
    "    else:\n",
    "        with h5py.File(fsampling) as f_h5py:\n",
    "            curr_arr = f_h5py['xy-domain'][var][:]\n",
    "        arr_reshaped = curr_arr.reshape((len(time), len(xy_zcoords), len(xy_ycoords), len(xy_xcoords)))\n",
    "        arr_transposed = np.transpose(arr_reshaped, axes=[0,3,2,1])\n",
    "        ds_xy[var] = (('time', 'x', 'y', 'z'), arr_transposed)\n",
    "ds_xy.to_netcdf(Path(outdir,f\"xy-domain.nc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1566e6d9-5234-4694-957e-a8c01ee76493",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reformat domain-wide xz data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cb0ab10-045a-4bbf-8ae7-acdd2aca450a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orybchuk/.conda-envs/daskenv202301/lib/python3.9/site-packages/dask/array/core.py:1701: FutureWarning: The `numpy.sort` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  warnings.warn(\n",
      "/home/orybchuk/.conda-envs/daskenv202301/lib/python3.9/site-packages/dask/array/core.py:1701: FutureWarning: The `numpy.sort` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  warnings.warn(\n",
      "/home/orybchuk/.conda-envs/daskenv202301/lib/python3.9/site-packages/dask/array/core.py:1701: FutureWarning: The `numpy.sort` function is not implemented by Dask array. You may want to use the da.map_blocks function or something similar to silence this warning. Your code may stop working in a future release.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Metadata for met masts\n",
    "with h5py.File(fsampling) as f_h5py:\n",
    "    f_xz = f_h5py['xz-domain']\n",
    "    ntsteps_xz = f_xz['velocityx'].shape[0]\n",
    "\n",
    "    da_xz_coords = da.from_array(f_xz['coordinates'], chunks=(-1,-1))\n",
    "    xz_xcoords = np.sort(np.unique(da_xz_coords[:,0]))\n",
    "    xz_ycoords = np.sort(np.unique(da_xz_coords[:,1]))\n",
    "    xz_zcoords = np.sort(np.unique(da_xz_coords[:,2]))\n",
    "    xz_time = np.round(np.arange(ntsteps_xz)*timestep*frequency_output,2)\n",
    "xz_coords = {'time':xz_time, 'x': xz_xcoords, 'y': xz_ycoords, 'z': xz_zcoords}\n",
    "\n",
    "## Reformat into an Xarray Dataset\n",
    "ds_xz = xr.Dataset(xz_coords)\n",
    "\n",
    "for var in varlist:\n",
    "    if use_dask:\n",
    "        raise NotImplementedError\n",
    "\n",
    "        # TODO: check the below code\n",
    "        curr_da = da.from_array(f_xz[var], chunks=chunksize_xz)\n",
    "        da_reshaped = curr_da.reshape((curr_da.shape[0], len(xz_zcoords), len(xz_ycoords), len(xz_xcoords)))\n",
    "        ds_xz[var] = (('time', 'z', 'y', 'x'), da_reshaped)\n",
    "    else:\n",
    "        with h5py.File(fsampling) as f_h5py:\n",
    "            curr_arr = f_h5py['xz-domain'][var][:]\n",
    "        arr_reshaped = curr_arr.reshape((len(time), len(xz_zcoords), len(xz_ycoords), len(xz_xcoords)))\n",
    "        arr_transposed = np.transpose(arr_reshaped, axes=[0,3,2,1])\n",
    "        ds_xz[var] = (('time', 'x', 'y', 'z'), arr_transposed)\n",
    "ds_xz.to_netcdf(Path(outdir,f\"xz-domain.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f84abd-6758-4fb8-9a99-02f499dde83c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daskenv202301",
   "language": "python",
   "name": "daskenv202301"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
